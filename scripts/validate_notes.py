#!/usr/bin/env python3
"""
Meeting Notes Validator
=======================
Validates meeting notes markdown files for completeness, formatting correctness,
and cross-reference consistency.

Usage:
    python validate_notes.py <meeting-notes.md>
    python validate_notes.py <meeting-notes.md> --lang zh_TW
    python validate_notes.py <meeting-notes.md> --json
    python validate_notes.py <meeting-notes.md> --transcript <transcript.txt>
    python validate_notes.py <meeting-notes.md> --transcript <transcript.txt> --glossary <glossary.md>
    python validate_notes.py <meeting-notes.md> --participants 'ç‹å°æ˜,æå°è¯,é™³å¤§åŒ'
    python validate_notes.py <meeting-notes.md> --participants attendees.txt
"""

import re
import sys
import json
import argparse
from pathlib import Path
from dataclasses import dataclass, field, asdict
from enum import Enum
from typing import Optional


class Severity(str, Enum):
    PASS = "pass"
    WARNING = "warning"
    ERROR = "error"


class Category(str, Enum):
    METADATA = "metadata"
    PARTICIPANTS = "participants"
    AGENDA = "agenda"
    DISCUSSION = "discussion"
    ACTION_ITEMS = "action_items"
    STRUCTURE = "structure"
    CROSS_REFERENCE = "cross_reference"
    TRANSCRIPT_COVERAGE = "transcript_coverage"


@dataclass
class ValidationResult:
    severity: Severity
    category: Category
    message_zh: str
    message_en: str

    def display(self, lang: str = "zh_TW") -> str:
        icons = {
            Severity.PASS: "âœ…",
            Severity.WARNING: "âš ï¸",
            Severity.ERROR: "âŒ",
        }
        icon = icons[self.severity]
        label_map = {
            ("zh_TW", Severity.PASS): "é€šé",
            ("zh_TW", Severity.WARNING): "è­¦å‘Š",
            ("zh_TW", Severity.ERROR): "éŒ¯èª¤",
            ("en", Severity.PASS): "PASS",
            ("en", Severity.WARNING): "WARNING",
            ("en", Severity.ERROR): "ERROR",
        }
        label = label_map.get((lang, self.severity), self.severity.value)
        msg = self.message_zh if lang == "zh_TW" else self.message_en
        return f"{icon} {label}: {msg}"


@dataclass
class ValidationReport:
    results: list[ValidationResult] = field(default_factory=list)
    file_path: str = ""

    def add(self, result: ValidationResult):
        self.results.append(result)

    @property
    def pass_count(self) -> int:
        return sum(1 for r in self.results if r.severity == Severity.PASS)

    @property
    def warning_count(self) -> int:
        return sum(1 for r in self.results if r.severity == Severity.WARNING)

    @property
    def error_count(self) -> int:
        return sum(1 for r in self.results if r.severity == Severity.ERROR)

    def display(self, lang: str = "zh_TW") -> str:
        lines = []
        if lang == "zh_TW":
            lines.append(f"## ğŸ“‹ æœƒè­°ç´€éŒ„é©—è­‰å ±å‘Š")
            lines.append(f"")
            lines.append(f"**æª”æ¡ˆ**: `{self.file_path}`")
        else:
            lines.append(f"## ğŸ“‹ Meeting Notes Validation Report")
            lines.append(f"")
            lines.append(f"**File**: `{self.file_path}`")
        lines.append("")

        # Group by category
        categories_zh = {
            Category.METADATA: "æœƒè­°åŸºæœ¬è³‡è¨Š",
            Category.PARTICIPANTS: "èˆ‡æœƒäººå“¡",
            Category.AGENDA: "æœƒè­°è­°ç¨‹",
            Category.DISCUSSION: "è¨è«–å…§å®¹",
            Category.ACTION_ITEMS: "å¾…è¾¦äº‹é …",
            Category.STRUCTURE: "æ¨¡æ¿çµæ§‹",
            Category.CROSS_REFERENCE: "äº¤å‰é©—è­‰",
            Category.TRANSCRIPT_COVERAGE: "é€å­—ç¨¿è¦†è“‹ç‡",
        }
        categories_en = {
            Category.METADATA: "Meeting Metadata",
            Category.PARTICIPANTS: "Participants",
            Category.AGENDA: "Agenda",
            Category.DISCUSSION: "Discussion",
            Category.ACTION_ITEMS: "Action Items",
            Category.STRUCTURE: "Template Structure",
            Category.CROSS_REFERENCE: "Cross-Reference",
            Category.TRANSCRIPT_COVERAGE: "Transcript Coverage",
        }
        cat_labels = categories_zh if lang == "zh_TW" else categories_en

        for cat in Category:
            cat_results = [r for r in self.results if r.category == cat]
            if cat_results:
                lines.append(f"### {cat_labels[cat]}")
                for r in cat_results:
                    lines.append(f"- {r.display(lang)}")
                lines.append("")

        # Summary
        lines.append("---")
        if lang == "zh_TW":
            lines.append(
                f"**ç¸½è¨ˆ**: {self.pass_count} é …é€šé, "
                f"{self.warning_count} é …è­¦å‘Š, "
                f"{self.error_count} é …éŒ¯èª¤"
            )
        else:
            lines.append(
                f"**Total**: {self.pass_count} passed, "
                f"{self.warning_count} warnings, "
                f"{self.error_count} errors"
            )

        return "\n".join(lines)

    def to_json(self) -> str:
        return json.dumps(
            {
                "file": self.file_path,
                "summary": {
                    "pass": self.pass_count,
                    "warning": self.warning_count,
                    "error": self.error_count,
                },
                "results": [
                    {
                        "severity": r.severity.value,
                        "category": r.category.value,
                        "message_zh": r.message_zh,
                        "message_en": r.message_en,
                    }
                    for r in self.results
                ],
            },
            ensure_ascii=False,
            indent=2,
        )


# ---------------------------------------------------------------------------
# Detection helpers
# ---------------------------------------------------------------------------

DATE_PATTERN = re.compile(r"\d{4}-\d{2}-\d{2}")
PLACEHOLDER_PATTERNS = [
    re.compile(r"\[.*?\]"),  # [placeholder text]
    re.compile(r"YYYY-MM-DD"),
    re.compile(r"HH:MM"),
]

# Bilingual section headers (EN and zh_TW)
REQUIRED_SECTIONS = {
    "metadata": [
        # EN
        r"Meeting\s+(Title|Information)",
        r"æœƒè­°(åç¨±|åŸºæœ¬è³‡è¨Š)",
    ],
    "participants": [
        r"Attend|Present",
        r"å‡ºå¸­äººå“¡|èˆ‡æœƒäººå“¡",
    ],
    "agenda": [
        r"Agenda",
        r"æœƒè­°è­°ç¨‹|è­°ç¨‹",
    ],
    "discussion": [
        r"Meeting\s+Summary|Discussion",
        r"æœƒè­°å…§å®¹æ‘˜è¦|æœƒè­°å…§å®¹",
    ],
    "next_meeting": [
        r"Next\s+Meeting",
        r"ä¸‹æ¬¡æœƒè­°",
    ],
}

ACTION_ITEM_PATTERN_EN = re.compile(
    r"- \[[ x]\]\s+(.+?)(?:\s*-\s*Owner:\s*(.+?))?\s*(?:-\s*Due:\s*(\S+))?\s*$",
    re.MULTILINE,
)
ACTION_ITEM_PATTERN_ZH = re.compile(
    r"- \[[ x]\]\s+(.+?)(?:\s*-\s*è² è²¬äºº:\s*(.+?))?\s*(?:-\s*æœŸé™:\s*(\S+))?\s*$",
    re.MULTILINE,
)


def detect_language(content: str) -> str:
    """Detect whether the meeting notes are primarily zh_TW or EN."""
    zh_markers = ["æœƒè­°", "è­°ç¨‹", "å‡ºå¸­", "æ±ºè­°", "å¾…è¾¦", "è² è²¬äºº", "æœŸé™", "ä¸»æŒäºº"]
    zh_count = sum(1 for m in zh_markers if m in content)
    return "zh_TW" if zh_count >= 3 else "en"


def extract_participants(content: str) -> list[str]:
    """Extract participant names from the attendee sections."""
    names: list[str] = []
    in_participant_section = False

    for line in content.splitlines():
        # Detect participant section headers
        if re.search(r"(å‡ºå¸­äººå“¡|Present|Attend|èˆ‡æœƒäººå“¡|è«‹å‡äººå“¡|On Leave|ç¼ºå¸­äººå“¡|Absent)", line, re.IGNORECASE):
            in_participant_section = True
            continue

        # Detect end of participant sections
        if in_participant_section and line.startswith("## "):
            in_participant_section = False
            continue

        if in_participant_section and line.strip().startswith("- "):
            name_part = line.strip().lstrip("- ").split("-")[0].strip()
            # Skip placeholders
            if name_part and not re.match(r"^\[.*\]$", name_part):
                names.append(name_part)

    return names


def extract_action_item_owners(content: str) -> list[str]:
    """Extract responsible person names from action items."""
    owners: list[str] = []
    for pattern in [ACTION_ITEM_PATTERN_EN, ACTION_ITEM_PATTERN_ZH]:
        for match in pattern.finditer(content):
            owner = match.group(2)
            if owner and not re.match(r"^\[.*\]$", owner.strip()):
                owners.append(owner.strip())
    return owners


def load_provided_participants(participants_arg: str) -> list[str]:
    """Load user-provided participant list.

    Accepts either:
      - A file path (one name per line)
      - A comma-separated string of names
    """
    path = Path(participants_arg)
    if path.exists() and path.is_file():
        content = path.read_text(encoding="utf-8")
        names = [line.strip().lstrip("- ").strip()
                 for line in content.splitlines()
                 if line.strip() and not line.strip().startswith("#")]
        return [n for n in names if n]

    # Treat as comma-separated inline list
    names = [n.strip() for n in re.split(r"[,ã€ï¼Œ]", participants_arg) if n.strip()]
    return names


def has_placeholder(text: str) -> bool:
    """Check if text contains obvious placeholder content."""
    for p in PLACEHOLDER_PATTERNS:
        if p.search(text):
            return True
    return False


# ---------------------------------------------------------------------------
# Validation checks
# ---------------------------------------------------------------------------

def validate_metadata(content: str, report: ValidationReport):
    """Check meeting metadata fields are present and filled in."""
    doc_lang = detect_language(content)

    # Required metadata fields (bilingual)
    metadata_fields = {
        "meeting_title": (
            [r"\*\*Meeting Title\*\*:\s*(.+)", r"\*\*æœƒè­°åç¨±\*\*:\s*(.+)"],
            "æœƒè­°åç¨±å·²å¡«å¯«", "Meeting title is filled in",
            "æœƒè­°åç¨±ç‚ºç©ºæˆ–ç‚ºä½”ä½ç¬¦", "Meeting title is empty or placeholder",
        ),
        "date": (
            [r"\*\*(Date|æœƒè­°æ—¥æœŸ)\*\*:\s*(.+)"],
            "æœƒè­°æ—¥æœŸå·²å¡«å¯«", "Meeting date is filled in",
            "æœƒè­°æ—¥æœŸç‚ºç©ºæˆ–ç‚ºä½”ä½ç¬¦", "Meeting date is empty or placeholder",
        ),
        "time": (
            [r"\*\*(Time|æœƒè­°æ™‚é–“)\*\*:\s*(.+)"],
            "æœƒè­°æ™‚é–“å·²å¡«å¯«", "Meeting time is filled in",
            "æœƒè­°æ™‚é–“ç‚ºç©ºæˆ–ç‚ºä½”ä½ç¬¦", "Meeting time is empty or placeholder",
        ),
        "location": (
            [r"\*\*(Location|æœƒè­°åœ°é»)\*\*:\s*(.+)"],
            "æœƒè­°åœ°é»å·²å¡«å¯«", "Meeting location is filled in",
            "æœƒè­°åœ°é»ç‚ºç©ºæˆ–ç‚ºä½”ä½ç¬¦", "Meeting location is empty or placeholder",
        ),
        "chairperson": (
            [r"\*\*(Chairperson|ä¸»æŒäºº)\*\*:\s*(.+)"],
            "ä¸»æŒäººå·²å¡«å¯«", "Chairperson is filled in",
            "ä¸»æŒäººç‚ºç©ºæˆ–ç‚ºä½”ä½ç¬¦", "Chairperson is empty or placeholder",
        ),
        "recorder": (
            [r"\*\*(Recorder|è¨˜éŒ„äºº)\*\*:\s*(.+)"],
            "è¨˜éŒ„äººå·²å¡«å¯«", "Recorder is filled in",
            "è¨˜éŒ„äººç‚ºç©ºæˆ–ç‚ºä½”ä½ç¬¦", "Recorder is empty or placeholder",
        ),
    }

    for field_name, (patterns, msg_zh_pass, msg_en_pass, msg_zh_fail, msg_en_fail) in metadata_fields.items():
        found = False
        is_placeholder = False
        for pat in patterns:
            match = re.search(pat, content)
            if match:
                found = True
                value = match.group(match.lastindex)
                if has_placeholder(value):
                    is_placeholder = True
                break

        if found and not is_placeholder:
            report.add(ValidationResult(Severity.PASS, Category.METADATA, msg_zh_pass, msg_en_pass))
        else:
            report.add(ValidationResult(Severity.ERROR, Category.METADATA, msg_zh_fail, msg_en_fail))

    # Validate date format
    date_match = re.search(r"\*\*(Date|æœƒè­°æ—¥æœŸ)\*\*:\s*(.+)", content)
    if date_match:
        date_val = date_match.group(2).strip()
        if DATE_PATTERN.fullmatch(date_val):
            report.add(ValidationResult(
                Severity.PASS, Category.METADATA,
                "æ—¥æœŸæ ¼å¼æ­£ç¢º (YYYY-MM-DD)", "Date format is correct (YYYY-MM-DD)"
            ))
        elif not has_placeholder(date_val):
            report.add(ValidationResult(
                Severity.WARNING, Category.METADATA,
                f"æ—¥æœŸæ ¼å¼å»ºè­°ä½¿ç”¨ YYYY-MM-DDï¼Œç›®å‰ç‚º: {date_val}",
                f"Date format should be YYYY-MM-DD, got: {date_val}"
            ))


def validate_participants(content: str, report: ValidationReport,
                         provided_participants: Optional[list[str]] = None):
    """Check participant sections and verify against user-provided list."""
    participants = extract_participants(content)

    if len(participants) > 0:
        report.add(ValidationResult(
            Severity.PASS, Category.PARTICIPANTS,
            f"å·²åˆ—å‡º {len(participants)} ä½èˆ‡æœƒäººå“¡",
            f"Found {len(participants)} participant(s) listed"
        ))
    else:
        report.add(ValidationResult(
            Severity.ERROR, Category.PARTICIPANTS,
            "æœªæ‰¾åˆ°ä»»ä½•èˆ‡æœƒäººå“¡ï¼ˆå‡ºå¸­äººå“¡æ¸…å–®ç‚ºç©ºæˆ–çš†ç‚ºä½”ä½ç¬¦ï¼‰",
            "No participants found (attendee list is empty or all placeholders)"
        ))

    # Cross-check against user-provided participant list
    if provided_participants:
        notes_participants_set = {p.strip() for p in participants}
        for name in provided_participants:
            if name in notes_participants_set:
                report.add(ValidationResult(
                    Severity.PASS, Category.PARTICIPANTS,
                    f"æŒ‡å®šå‡ºå¸­è€…ã€Œ{name}ã€å·²è¨˜éŒ„åœ¨æœƒè­°ç´€éŒ„ä¸­",
                    f"Specified attendee \"{name}\" is recorded in meeting notes"
                ))
            else:
                # Check if partially present in content (e.g. in discussion body)
                if name in content:
                    report.add(ValidationResult(
                        Severity.WARNING, Category.PARTICIPANTS,
                        f"æŒ‡å®šå‡ºå¸­è€…ã€Œ{name}ã€å‡ºç¾åœ¨å…§æ–‡ä½†æœªåˆ—å…¥å‡ºå¸­äººå“¡åå–®",
                        f"Specified attendee \"{name}\" appears in content but NOT in participant list"
                    ))
                else:
                    report.add(ValidationResult(
                        Severity.WARNING, Category.PARTICIPANTS,
                        f"æŒ‡å®šå‡ºå¸­è€…ã€Œ{name}ã€æœªå‡ºç¾åœ¨æœƒè­°ç´€éŒ„ä¸­",
                        f"Specified attendee \"{name}\" is NOT found in meeting notes"
                    ))

        # Also check if notes have participants not in the provided list
        provided_set = set(provided_participants)
        for p in participants:
            if p not in provided_set:
                report.add(ValidationResult(
                    Severity.WARNING, Category.PARTICIPANTS,
                    f"æœƒè­°ç´€éŒ„ä¸­çš„ã€Œ{p}ã€ä¸åœ¨æŒ‡å®šå‡ºå¸­åå–®ä¸­ï¼Œè«‹ç¢ºèªæ˜¯å¦æ­£ç¢º",
                    f"\"{p}\" in meeting notes is NOT in the provided attendee list â€” please verify"
                ))


def validate_agenda(content: str, report: ValidationReport):
    """Check agenda items exist."""
    # Look for numbered list items after agenda header
    agenda_section = False
    agenda_items = []
    for line in content.splitlines():
        if re.search(r"(##\s*(Agenda|æœƒè­°è­°ç¨‹))", line, re.IGNORECASE):
            agenda_section = True
            continue
        if agenda_section and line.startswith("## "):
            break
        if agenda_section and re.match(r"\d+\.\s+", line.strip()):
            item_text = re.sub(r"^\d+\.\s+", "", line.strip())
            if not re.match(r"^\[.*\]$", item_text):
                agenda_items.append(item_text)

    if len(agenda_items) > 0:
        report.add(ValidationResult(
            Severity.PASS, Category.AGENDA,
            f"å·²åˆ—å‡º {len(agenda_items)} é …è­°ç¨‹",
            f"Found {len(agenda_items)} agenda item(s)"
        ))
    else:
        report.add(ValidationResult(
            Severity.WARNING, Category.AGENDA,
            "æœªæ‰¾åˆ°å¯¦éš›è­°ç¨‹é …ç›®ï¼ˆå¯èƒ½çš†ç‚ºä½”ä½ç¬¦ï¼‰",
            "No actual agenda items found (may all be placeholders)"
        ))


def validate_discussion(content: str, report: ValidationReport):
    """Check discussion sections have content."""
    # Find topic headers (### [Topic X: ...] or ### [è­°é¡ŒX: ...])
    topic_pattern = re.compile(r"###\s+(.+)")
    topics = []
    current_topic: Optional[str] = None
    current_content_lines: list[str] = []

    for line in content.splitlines():
        topic_match = topic_pattern.match(line)
        if topic_match:
            # Save previous topic
            if current_topic is not None:
                topics.append((current_topic, "\n".join(current_content_lines)))
            current_topic = topic_match.group(1).strip()
            current_content_lines = []
        elif current_topic is not None:
            current_content_lines.append(line)

    # Save last topic
    if current_topic is not None:
        topics.append((current_topic, "\n".join(current_content_lines)))

    # Filter to only discussion topics (exclude non-discussion ### headers)
    exclude_headers = [
        r"å‡ºå¸­äººå“¡", r"è«‹å‡äººå“¡", r"ç¼ºå¸­äººå“¡",
        r"Present", r"On Leave", r"Absent",
        r"æŠ€è¡“è¡“èª", r"å•†æ¥­è¡“èª", r"éƒ¨é–€åç¨±",
        r"ä¸­æ–‡å§“å", r"è‹±æ–‡å§“å", r"æœƒè­°ç›¸é—œ", r"å‹•è©",
    ]
    discussion_topics = [
        (name, body) for name, body in topics
        if not any(re.search(pat, name) for pat in exclude_headers)
        and re.search(r"(è¨è«–é‡é»|Key Discussion|æ±ºè­°|Decision|å¾…è¾¦|Action)", body, re.IGNORECASE)
    ]

    if len(discussion_topics) > 0:
        report.add(ValidationResult(
            Severity.PASS, Category.DISCUSSION,
            f"æ‰¾åˆ° {len(discussion_topics)} å€‹è¨è«–è­°é¡Œ",
            f"Found {len(discussion_topics)} discussion topic(s)"
        ))

        for topic_name, topic_body in discussion_topics:
            has_discussion = bool(re.search(r"(è¨è«–é‡é»|Key Discussion)", topic_body, re.IGNORECASE))
            has_decision = bool(re.search(r"(æ±ºè­°äº‹é …|Decision)", topic_body, re.IGNORECASE))
            has_action = bool(re.search(r"(å¾…è¾¦äº‹é …|Action Item)", topic_body, re.IGNORECASE))

            if not has_decision:
                report.add(ValidationResult(
                    Severity.WARNING, Category.DISCUSSION,
                    f"è­°é¡Œã€Œ{topic_name}ã€ç¼ºå°‘æ±ºè­°äº‹é …",
                    f"Topic \"{topic_name}\" is missing decisions"
                ))
    else:
        report.add(ValidationResult(
            Severity.WARNING, Category.DISCUSSION,
            "æœªæ‰¾åˆ°åŒ…å«å®Œæ•´è¨è«–å…§å®¹çš„è­°é¡Œå€å¡Š",
            "No discussion topic blocks with complete content found"
        ))


def validate_action_items(content: str, report: ValidationReport):
    """Check action items have required fields."""
    action_items_en = ACTION_ITEM_PATTERN_EN.findall(content)
    action_items_zh = ACTION_ITEM_PATTERN_ZH.findall(content)
    all_items = action_items_en + action_items_zh

    # Also find checkbox lines that might not fully match
    checkbox_lines = re.findall(r"- \[[ x]\]\s+(.+)", content)

    if len(checkbox_lines) == 0:
        report.add(ValidationResult(
            Severity.WARNING, Category.ACTION_ITEMS,
            "æœªæ‰¾åˆ°ä»»ä½•å¾…è¾¦äº‹é …",
            "No action items found"
        ))
        return

    placeholder_items = [line for line in checkbox_lines if has_placeholder(line)]
    real_items = [line for line in checkbox_lines if not has_placeholder(line)]

    if len(real_items) == 0:
        report.add(ValidationResult(
            Severity.WARNING, Category.ACTION_ITEMS,
            "æ‰€æœ‰å¾…è¾¦äº‹é …çš†ç‚ºä½”ä½ç¬¦",
            "All action items are placeholders"
        ))
        return

    report.add(ValidationResult(
        Severity.PASS, Category.ACTION_ITEMS,
        f"æ‰¾åˆ° {len(real_items)} é …å¾…è¾¦äº‹é …",
        f"Found {len(real_items)} action item(s)"
    ))

    # Check each real action item for owner and due date
    for item_line in real_items:
        has_owner = bool(re.search(r"(è² è²¬äºº|Owner)\s*:\s*\S+", item_line))
        has_due = bool(re.search(r"(æœŸé™|Due)\s*:\s*\S+", item_line))

        if not has_owner:
            short_desc = item_line[:40] + ("..." if len(item_line) > 40 else "")
            report.add(ValidationResult(
                Severity.WARNING, Category.ACTION_ITEMS,
                f"å¾…è¾¦äº‹é …ç¼ºå°‘è² è²¬äºº: ã€Œ{short_desc}ã€",
                f"Action item missing owner: \"{short_desc}\""
            ))

        if not has_due:
            short_desc = item_line[:40] + ("..." if len(item_line) > 40 else "")
            report.add(ValidationResult(
                Severity.WARNING, Category.ACTION_ITEMS,
                f"å¾…è¾¦äº‹é …ç¼ºå°‘æœŸé™: ã€Œ{short_desc}ã€",
                f"Action item missing due date: \"{short_desc}\""
            ))


def validate_structure(content: str, report: ValidationReport):
    """Check required template sections exist."""
    for section_name, patterns in REQUIRED_SECTIONS.items():
        found = any(re.search(pat, content, re.IGNORECASE) for pat in patterns)
        section_labels = {
            "metadata": ("æœƒè­°åŸºæœ¬è³‡è¨Šå€å¡Š", "Meeting information section"),
            "participants": ("èˆ‡æœƒäººå“¡å€å¡Š", "Participants section"),
            "agenda": ("è­°ç¨‹å€å¡Š", "Agenda section"),
            "discussion": ("è¨è«–å…§å®¹å€å¡Š", "Discussion section"),
            "next_meeting": ("ä¸‹æ¬¡æœƒè­°å€å¡Š", "Next meeting section"),
        }
        zh_label, en_label = section_labels[section_name]

        if found:
            report.add(ValidationResult(
                Severity.PASS, Category.STRUCTURE,
                f"{zh_label}å­˜åœ¨", f"{en_label} exists"
            ))
        else:
            report.add(ValidationResult(
                Severity.ERROR, Category.STRUCTURE,
                f"ç¼ºå°‘{zh_label}", f"Missing {en_label}"
            ))


def validate_cross_references(content: str, report: ValidationReport,
                              provided_participants: Optional[list[str]] = None):
    """Check that action item owners appear in participant list."""
    participants = extract_participants(content)
    owners = extract_action_item_owners(content)

    if not owners:
        return

    # Use provided participants as authoritative source if available,
    # otherwise fall back to participants extracted from the notes
    if provided_participants:
        participant_set = set(provided_participants)
    elif participants:
        participant_set = {p.strip() for p in participants}
    else:
        return

    for owner in owners:
        owner_clean = owner.strip()
        if owner_clean in participant_set:
            report.add(ValidationResult(
                Severity.PASS, Category.CROSS_REFERENCE,
                f"å¾…è¾¦è² è²¬äººã€Œ{owner_clean}ã€å·²åœ¨èˆ‡æœƒäººå“¡åå–®ä¸­",
                f"Action item owner \"{owner_clean}\" is in participant list"
            ))
        else:
            report.add(ValidationResult(
                Severity.WARNING, Category.CROSS_REFERENCE,
                f"å¾…è¾¦è² è²¬äººã€Œ{owner_clean}ã€æœªå‡ºç¾åœ¨èˆ‡æœƒäººå“¡åå–®ä¸­",
                f"Action item owner \"{owner_clean}\" is NOT in participant list"
            ))


# ---------------------------------------------------------------------------
# Glossary & Transcript Coverage
# ---------------------------------------------------------------------------

def load_glossary(glossary_path: str) -> dict[str, list[str]]:
    """Load glossary and build a correction map: {correct_term: [error_variants]}."""
    correction_map: dict[str, list[str]] = {}
    path = Path(glossary_path)
    if not path.exists():
        return correction_map

    content = path.read_text(encoding="utf-8")
    # Pattern: "- æ­£ç¢ºè© (èªªæ˜) - å¸¸è¦‹éŒ¯èª¤: éŒ¯èª¤1ã€éŒ¯èª¤2"
    # or:      "- æ­£ç¢ºè© - å¸¸è¦‹éŒ¯èª¤: éŒ¯èª¤1ã€éŒ¯èª¤2"
    # or:      "- æ­£ç¢ºè© - Common errors: err1, err2"
    pattern = re.compile(
        r"^- (.+?)(?:\s*\(.+?\))?\s*-\s*(?:å¸¸è¦‹éŒ¯èª¤|Common errors?):\s*(.+)$",
        re.MULTILINE,
    )
    for match in pattern.finditer(content):
        correct_term = match.group(1).strip()
        errors_raw = match.group(2).strip()
        # Split by ã€ or , or ã€
        errors = [e.strip() for e in re.split(r"[ã€,ï¼Œ]", errors_raw) if e.strip()]
        correction_map[correct_term] = errors

    return correction_map


def apply_glossary_corrections(text: str, correction_map: dict[str, list[str]]) -> str:
    """Apply glossary corrections to raw transcript text."""
    corrected = text
    for correct_term, error_variants in correction_map.items():
        for error in error_variants:
            if error in corrected:
                corrected = corrected.replace(error, correct_term)
    return corrected


@dataclass
class KeyFact:
    """A key fact extracted from the transcript."""
    category: str       # "person", "number", "date", "decision", "action", "term"
    value: str          # The extracted value
    context: str        # Surrounding text for display
    search_terms: list[str]  # Terms to search for in meeting notes


def extract_key_facts(
    transcript: str,
    correction_map: dict[str, list[str]],
) -> list[KeyFact]:
    """Extract key facts from a corrected transcript."""
    facts: list[KeyFact] = []
    seen: set[str] = set()

    # --- 1. Person names (from glossary) ---
    glossary_names_section_terms = set()
    for term in correction_map:
        # Heuristic: Chinese names are 2-4 chars, English names contain spaces
        if (2 <= len(term) <= 4 and re.match(r"^[\u4e00-\u9fff]+$", term)) or \
           re.match(r"^[A-Z][a-z]+ [A-Z]", term):
            glossary_names_section_terms.add(term)

    for name in glossary_names_section_terms:
        if name in transcript and name not in seen:
            # Get context (up to 20 chars around the match)
            idx = transcript.index(name)
            start = max(0, idx - 15)
            end = min(len(transcript), idx + len(name) + 15)
            context = "..." + transcript[start:end] + "..."
            facts.append(KeyFact("person", name, context, [name]))
            seen.add(name)

    # --- 2. Numbers, percentages, monetary amounts ---
    number_patterns = [
        # Percentages: 80%, ç™¾åˆ†ä¹‹å…«å
        (r"\d+\.?\d*\s*%", "number"),
        (r"ç™¾åˆ†ä¹‹[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+", "number"),
        # Monetary: $5M, 300è¬, 5000å…ƒ, NT\$..., USD...
        (r"(?:NT\$|USD?|\$)\s*[\d,.]+[KMBkmb]?", "number"),
        (r"\d+(?:\.\d+)?\s*[è¬å„„åƒç™¾](?:å…ƒ|å¡Š)?", "number"),
        (r"\d{1,3}(?:,\d{3})+(?:\.\d+)?\s*å…ƒ?", "number"),
        # Large standalone numbers (5+ digits or with commas) â€” likely significant
        (r"\d{5,}", "number"),
        # Specific quantities: 3å€‹æœˆ, 5äºº, 10å¤©, 2é€±
        (r"\d+\s*(?:å€‹æœˆ|å€‹äºº|äºº|å¤©|é€±|å‘¨|å¹´|å­£|æ¬¡|ä»¶|å°|çµ„|æ‰¹|ä»½|é …)", "number"),
    ]
    for pat_str, cat in number_patterns:
        for match in re.finditer(pat_str, transcript):
            value = match.group().strip()
            if value not in seen and len(value) >= 2:
                idx = match.start()
                start = max(0, idx - 15)
                end = min(len(transcript), match.end() + 15)
                context = "..." + transcript[start:end] + "..."
                facts.append(KeyFact(cat, value, context, [value]))
                seen.add(value)

    # --- 3. Dates ---
    date_patterns = [
        r"\d{4}[-/]\d{1,2}[-/]\d{1,2}",
        r"\d{1,2}æœˆ\d{1,2}[æ—¥è™Ÿ]",
        r"(?:ä¸‹|ä¸Š|é€™)(?:é€±|å‘¨|ç¦®æ‹œ)[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©]",
        r"(?:æ˜|å¾Œ|å‰|æ˜¨)å¤©",
        r"(?:ä¸‹|ä¸Š|é€™)å€‹æœˆ",
        r"Q[1-4]",
        r"ç¬¬[ä¸€äºŒä¸‰å››]å­£",
    ]
    for pat_str in date_patterns:
        for match in re.finditer(pat_str, transcript):
            value = match.group().strip()
            if value not in seen:
                idx = match.start()
                start = max(0, idx - 15)
                end = min(len(transcript), match.end() + 15)
                context = "..." + transcript[start:end] + "..."
                facts.append(KeyFact("date", value, context, [value]))
                seen.add(value)

    # --- 4. Decision / conclusion sentences ---
    decision_markers = [
        r"æ±ºå®š", r"æ±ºè­°", r"åŒæ„", r"é€šé", r"å¦æ±º", r"æ‹æ¿", r"ç¢ºèª",
        r"çµè«–æ˜¯", r"æœ€çµ‚æ–¹æ¡ˆ", r"æˆ‘å€‘æ±ºå®š", r"å¤§å®¶åŒæ„",
        r"decided", r"agreed", r"approved", r"conclusion",
    ]
    for marker in decision_markers:
        for match in re.finditer(marker, transcript, re.IGNORECASE):
            idx = match.start()
            # Find the sentence containing this marker (bounded by newlines or sentence-end punctuation)
            line_start = transcript.rfind("\n", 0, idx)
            line_start = line_start + 1 if line_start != -1 else 0
            line_end = transcript.find("\n", idx)
            line_end = line_end if line_end != -1 else len(transcript)
            sentence = transcript[line_start:line_end].strip()
            # Clean up numbering prefixes like "1. " "2. "
            sentence_clean = re.sub(r"^\d+\.\s*", "", sentence).strip()
            # Skip pure header/label lines (e.g., "æ±ºå®šäº‹é …ï¼š")
            if re.match(r"^.{0,6}[ï¼š:]\s*$", sentence_clean):
                continue
            if sentence_clean not in seen and len(sentence_clean) >= 4:
                context = "..." + sentence + "..."
                # Search terms: the full sentence and core keywords within it
                search_terms = [sentence_clean]
                # Also add a shorter key phrase (first 20 chars) for fuzzy matching
                if len(sentence_clean) > 20:
                    search_terms.append(sentence_clean[:20])
                facts.append(KeyFact("decision", sentence_clean, context, search_terms))
                seen.add(sentence_clean)

    # --- 5. Action / assignment sentences ---
    action_markers = [
        r"è² è²¬", r"è«‹.{1,6}(?:è™•ç†|å®Œæˆ|è² è²¬|æº–å‚™|è·Ÿé€²|è¿½è¹¤)",
        r"è¦åœ¨.{0,10}ä¹‹å‰", r"æˆªæ­¢æ—¥æœŸ", r"deadline",
        r"assigned to", r"responsible for", r"action item",
    ]
    for marker in action_markers:
        for match in re.finditer(marker, transcript, re.IGNORECASE):
            idx = match.start()
            # Extract the full line containing this marker
            line_start = transcript.rfind("\n", 0, idx)
            line_start = line_start + 1 if line_start != -1 else 0
            line_end = transcript.find("\n", idx)
            line_end = line_end if line_end != -1 else len(transcript)
            sentence = transcript[line_start:line_end].strip()
            sentence_clean = re.sub(r"^\d+\.\s*", "", sentence).strip()
            if sentence_clean not in seen and len(sentence_clean) >= 4:
                context = "..." + sentence + "..."
                search_terms = [sentence_clean]
                if len(sentence_clean) > 20:
                    search_terms.append(sentence_clean[:20])
                facts.append(KeyFact("action", sentence_clean, context, search_terms))
                seen.add(sentence_clean)

    # --- 6. Glossary technical/business terms mentioned ---
    non_name_terms = set(correction_map.keys()) - glossary_names_section_terms
    for term in non_name_terms:
        if term in transcript and term not in seen:
            idx = transcript.index(term)
            start = max(0, idx - 15)
            end = min(len(transcript), idx + len(term) + 15)
            context = "..." + transcript[start:end] + "..."
            facts.append(KeyFact("term", term, context, [term]))
            seen.add(term)

    return facts


def validate_transcript_coverage(
    transcript_path: str,
    notes_content: str,
    report: ValidationReport,
    glossary_path: Optional[str] = None,
):
    """Validate that key facts from the transcript appear in the meeting notes."""
    transcript_file = Path(transcript_path)
    if not transcript_file.exists():
        report.add(ValidationResult(
            Severity.ERROR, Category.TRANSCRIPT_COVERAGE,
            f"æ‰¾ä¸åˆ°é€å­—ç¨¿æª”æ¡ˆ: {transcript_path}",
            f"Transcript file not found: {transcript_path}",
        ))
        return

    raw_transcript = transcript_file.read_text(encoding="utf-8")

    # Load glossary if provided
    correction_map: dict[str, list[str]] = {}
    if glossary_path:
        correction_map = load_glossary(glossary_path)

    # Apply corrections to transcript
    corrected_transcript = apply_glossary_corrections(raw_transcript, correction_map)

    # Extract key facts
    facts = extract_key_facts(corrected_transcript, correction_map)

    if not facts:
        report.add(ValidationResult(
            Severity.WARNING, Category.TRANSCRIPT_COVERAGE,
            "æœªèƒ½å¾é€å­—ç¨¿ä¸­æå–åˆ°é—œéµäº‹å¯¦ï¼ˆå¯èƒ½é€å­—ç¨¿å…§å®¹éçŸ­æˆ–æ ¼å¼ç‰¹æ®Šï¼‰",
            "Could not extract key facts from transcript (content may be too short or in unusual format)",
        ))
        return

    # Category labels for display
    cat_labels_zh = {
        "person": "ğŸ‘¤ äººå", "number": "ğŸ”¢ æ•¸å­—", "date": "ğŸ“… æ—¥æœŸ",
        "decision": "ğŸ”¨ æ±ºç­–", "action": "ğŸ“Œ è¡Œå‹•", "term": "ğŸ“– è¡“èª",
    }
    cat_labels_en = {
        "person": "ğŸ‘¤ Person", "number": "ğŸ”¢ Number", "date": "ğŸ“… Date",
        "decision": "ğŸ”¨ Decision", "action": "ğŸ“Œ Action", "term": "ğŸ“– Term",
    }

    found_count = 0
    missing_facts: list[KeyFact] = []

    def normalize(text: str) -> str:
        """Remove whitespace and common punctuation differences for fuzzy matching."""
        return re.sub(r"[\s\u3000\u00a0]+", "", text).lower()

    notes_normalized = normalize(notes_content)

    for fact in facts:
        # Check if any of the search terms appear in the meeting notes
        # Try both exact match and normalized (whitespace-insensitive) match
        is_found = any(term in notes_content for term in fact.search_terms)
        if not is_found:
            is_found = any(normalize(term) in notes_normalized for term in fact.search_terms)
        if is_found:
            found_count += 1
        else:
            missing_facts.append(fact)

    total = len(facts)
    coverage_pct = (found_count / total * 100) if total > 0 else 0

    # Overall coverage report
    if coverage_pct >= 80:
        report.add(ValidationResult(
            Severity.PASS, Category.TRANSCRIPT_COVERAGE,
            f"é€å­—ç¨¿è¦†è“‹ç‡: {coverage_pct:.0f}% ({found_count}/{total} é …é—œéµäº‹å¯¦å·²è¨˜éŒ„)",
            f"Transcript coverage: {coverage_pct:.0f}% ({found_count}/{total} key facts recorded)",
        ))
    elif coverage_pct >= 50:
        report.add(ValidationResult(
            Severity.WARNING, Category.TRANSCRIPT_COVERAGE,
            f"é€å­—ç¨¿è¦†è“‹ç‡åä½: {coverage_pct:.0f}% ({found_count}/{total} é …é—œéµäº‹å¯¦å·²è¨˜éŒ„)",
            f"Low transcript coverage: {coverage_pct:.0f}% ({found_count}/{total} key facts recorded)",
        ))
    else:
        report.add(ValidationResult(
            Severity.ERROR, Category.TRANSCRIPT_COVERAGE,
            f"é€å­—ç¨¿è¦†è“‹ç‡ä¸è¶³: {coverage_pct:.0f}% ({found_count}/{total} é …é—œéµäº‹å¯¦å·²è¨˜éŒ„)",
            f"Insufficient transcript coverage: {coverage_pct:.0f}% ({found_count}/{total} key facts recorded)",
        ))

    # Report each missing fact
    for fact in missing_facts:
        zh_cat = cat_labels_zh.get(fact.category, fact.category)
        en_cat = cat_labels_en.get(fact.category, fact.category)
        report.add(ValidationResult(
            Severity.WARNING, Category.TRANSCRIPT_COVERAGE,
            f"æœªè¨˜éŒ„ {zh_cat}ã€Œ{fact.value}ã€â€” å‡ºè™•: {fact.context}",
            f"Missing {en_cat} \"{fact.value}\" â€” source: {fact.context}",
        ))


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def validate(file_path: str, transcript_path: Optional[str] = None,
             glossary_path: Optional[str] = None,
             participants: Optional[list[str]] = None) -> ValidationReport:
    """Run all validations on a meeting notes file."""
    path = Path(file_path)
    content = path.read_text(encoding="utf-8")

    report = ValidationReport(file_path=str(path.name))

    validate_metadata(content, report)
    validate_participants(content, report, provided_participants=participants)
    validate_agenda(content, report)
    validate_discussion(content, report)
    validate_action_items(content, report)
    validate_structure(content, report)
    validate_cross_references(content, report, provided_participants=participants)

    # Transcript coverage validation (optional)
    if transcript_path:
        validate_transcript_coverage(transcript_path, content, report, glossary_path)

    return report


def main():
    parser = argparse.ArgumentParser(
        description="Validate meeting notes markdown files"
    )
    parser.add_argument(
        "file",
        help="Path to the meeting notes markdown file to validate",
    )
    parser.add_argument(
        "--transcript",
        default=None,
        help="Path to the original transcript file for coverage validation",
    )
    parser.add_argument(
        "--glossary",
        default=None,
        help="Path to the glossary file for term correction (used with --transcript)",
    )
    parser.add_argument(
        "--participants",
        default=None,
        help="User-provided participant list: a file path (one name per line) "
             "or comma-separated names (e.g. 'ç‹å°æ˜,æå°è¯,é™³å¤§åŒ')",
    )
    parser.add_argument(
        "--lang",
        choices=["zh_TW", "en"],
        default=None,
        help="Output language (auto-detected if not specified)",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        dest="output_json",
        help="Output results as JSON",
    )

    args = parser.parse_args()
    file_path = Path(args.file)

    if not file_path.exists():
        print(f"Error: File not found: {file_path}", file=sys.stderr)
        sys.exit(1)

    # Load user-provided participants
    provided_participants = None
    if args.participants:
        provided_participants = load_provided_participants(args.participants)
        if provided_participants:
            print(f"ğŸ“‹ Using provided participant list: {', '.join(provided_participants)}")
        else:
            print("âš ï¸  --participants provided but no names could be parsed.", file=sys.stderr)

    report = validate(str(file_path), args.transcript, args.glossary, provided_participants)

    if args.output_json:
        print(report.to_json())
    else:
        lang = args.lang or detect_language(file_path.read_text(encoding="utf-8"))
        print(report.display(lang))

    # Exit code: 1 if any errors, 0 otherwise
    sys.exit(1 if report.error_count > 0 else 0)


if __name__ == "__main__":
    main()
